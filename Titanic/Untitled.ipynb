{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#reading data\n",
    "data_train = pd.read_csv('Data/train.csv')\n",
    "data_test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling null values\n",
    "data_cleaner = [data_train,data_test]\n",
    "for data in data_cleaner:\n",
    "    data.drop(['Cabin','Ticket','PassengerId'],axis=1,inplace=True)\n",
    "    data['Age'].fillna(data['Age'].median(),inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(),inplace=True)\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#create new feature\n",
    "for data in data_cleaner:\n",
    "    data['Title'] = data['Name'].apply(lambda x : x.split(',')[1].split('.')[0])\n",
    "    min_title = data['Title'].value_counts() < 10\n",
    "    data['Title'] = data['Title'].apply(lambda x: 'Misc' if min_title.loc[x] == True else x)\n",
    "    data['AgeBin'] = pd.cut(data['Age'].astype(int),5)\n",
    "    data['FareBin'] = pd.qcut(data['Fare'].astype(int),4)\n",
    "    data['Family_size'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['Is_Alone'] = 1\n",
    "    data['Is_Alone'].loc[data['Family_size'] > 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#encode data\n",
    "encoder = LabelEncoder()\n",
    "for data in data_cleaner:\n",
    "    data['Sex_Code'] = encoder.fit_transform(data['Sex'])\n",
    "    data['Age_Code'] = encoder.fit_transform(data['AgeBin'])\n",
    "    data['Fare_Code'] = encoder.fit_transform(data['FareBin'])\n",
    "    data['Embarked_Code'] = encoder.fit_transform(data['Embarked'])\n",
    "    data['Title_Code'] = encoder.fit_transform(data['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = ['Age','Pclass','Sex','Family_size','Title','FareBin','Embarked']\n",
    "data_train_x_calc = ['Pclass','Family_size','Is_Alone','Sex_Code','Age_Code','Fare_Code','Embarked_Code','Title_Code']\n",
    "Target = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Correlation by: Pclass\n",
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Sex\n",
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Family_size\n",
      "   Family_size  Survived\n",
      "0            1  0.303538\n",
      "1            2  0.552795\n",
      "2            3  0.578431\n",
      "3            4  0.724138\n",
      "4            5  0.200000\n",
      "5            6  0.136364\n",
      "6            7  0.333333\n",
      "7            8  0.000000\n",
      "8           11  0.000000\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Title\n",
      "     Title  Survived\n",
      "0   Master  0.575000\n",
      "1     Miss  0.697802\n",
      "2       Mr  0.156673\n",
      "3      Mrs  0.792000\n",
      "4     Misc  0.444444\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: FareBin\n",
      "         FareBin  Survived\n",
      "0  (-0.001, 7.0]  0.215768\n",
      "1    (7.0, 14.0]  0.287037\n",
      "2   (14.0, 31.0]  0.457399\n",
      "3  (31.0, 512.0]  0.597156\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Embarked\n",
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in data_train_x:\n",
    "    if data_train[x].dtype != 'float64' :\n",
    "        print('Survival Correlation by:', x)\n",
    "        print(data_train[[x, Target[0]]].groupby(x, as_index=False).mean())\n",
    "        print('-'*10, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create Correlation df\n",
    "corr = data_train.corr()\n",
    "#Plot figsize\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "#Generate Color Map\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "#Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(corr, \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 })\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE DT Parameters:  {'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 0, 'splitter': 'best'}\n",
      "BEFORE DT Training w/bin score mean: 89.57\n",
      "BEFORE DT Test w/bin score mean: 81.98\n",
      "BEFORE DT Test w/bin score 3*std: +/- 6.17\n",
      "----------\n",
      "AFTER DT Parameters:  {'criterion': 'entropy', 'max_depth': 4, 'random_state': 0}\n",
      "AFTER DT Training w/bin score mean: 89.28\n",
      "AFTER DT Test w/bin score mean: 87.45\n",
      "AFTER DT Test w/bin score 3*std: +/- 6.14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "cv_split = model_selection.ShuffleSplit(n_splits=10, test_size=0.3, train_size=0.6, random_state=0)\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "base_results = model_selection.cross_validate(dtree, data_train[data_train_x_calc], data_train[Target], cv  = cv_split,return_train_score=True)\n",
    "dtree.fit(data_train[data_train_x_calc], data_train[Target])\n",
    "\n",
    "print('BEFORE DT Parameters: ', dtree.get_params())\n",
    "print(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100))\n",
    "print(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print(\"BEFORE DT Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "dtree_no_param = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n",
    "              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n",
    "              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n",
    "              #'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n",
    "              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n",
    "              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n",
    "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n",
    "             }\n",
    "\n",
    "tune_model = model_selection.GridSearchCV(dtree_no_param,param_grid=param_grid,scoring='roc_auc',cv = cv_split,return_train_score=True)\n",
    "tune_model.fit(data_train[data_train_x_calc],data_train[Target])\n",
    "\n",
    "print('AFTER DT Parameters: ', tune_model.best_params_)\n",
    "#print(tune_model.cv_results_['mean_train_score'])\n",
    "print(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n",
    "#print(tune_model.cv_results_['mean_test_score'])\n",
    "print(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE RFE :  {'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 0, 'splitter': 'best'}\n",
      "BEFORE RFE Training w/bin score mean: 89.57\n",
      "BEFORE RFE Test w/bin score mean: 81.98\n",
      "BEFORE RFE Test w/bin score 3*std: +/- 6.17\n",
      "----------\n",
      "AFTER DT RFE Training Shape New:  (891, 6)\n",
      "AFTER DT RFE Training Columns New:  ['Pclass' 'Family_size' 'Sex_Code' 'Age_Code' 'Fare_Code' 'Title_Code']\n",
      "AFTER DT RFE Training w/bin score mean: 88.30\n",
      "AFTER DT RFE Test w/bin score mean: 82.65\n",
      "AFTER DT RFE Test w/bin score 3*std: +/- 5.76\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER DT RFE Tuned Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
      "AFTER DT RFE Tuned Training w/bin score mean: 89.37\n",
      "AFTER DT RFE Tuned Test w/bin score mean: 87.26\n",
      "AFTER DT RFE Tuned Test w/bin score 3*std: +/- 6.58\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_selection\n",
    "\n",
    "print('BEFORE RFE : ', dtree.get_params())\n",
    "print(\"BEFORE RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100))\n",
    "print(\"BEFORE RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print(\"BEFORE RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "dtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\n",
    "dtree_rfe.fit(data_train[data_train_x_calc], data_train[Target])\n",
    "\n",
    "X_rfe = data_train[data_train_x_calc].columns.values[dtree_rfe.get_support()]\n",
    "rfe_results = model_selection.cross_validate(dtree, data_train[X_rfe], data_train[Target], cv  = cv_split,return_train_score=True)\n",
    "\n",
    "print('AFTER DT RFE Training Shape New: ', data_train[X_rfe].shape) \n",
    "print('AFTER DT RFE Training Columns New: ', X_rfe)\n",
    "\n",
    "print(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \n",
    "print(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\n",
    "print(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "best_model = model_selection.GridSearchCV(dtree_no_param,param_grid=param_grid,scoring='roc_auc',cv = cv_split,return_train_score=True)\n",
    "best_model.fit(data_train[X_rfe],data_train[Target])\n",
    "\n",
    "print('AFTER DT RFE Tuned Parameters: ', best_model.best_params_)\n",
    "#print(rfe_tune_model.cv_results_['mean_train_score'])\n",
    "print(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(best_model.cv_results_['mean_train_score'][best_model.best_index_]*100)) \n",
    "#print(rfe_tune_model.cv_results_['mean_test_score'])\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(best_model.cv_results_['mean_test_score'][best_model.best_index_]*100))\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(best_model.cv_results_['std_test_score'][best_model.best_index_]*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_test.drop(['Name','Sex','Age','SibSp','Parch','Embarked','Title','AgeBin','FareBin','Embarked_Code','Fare','Is_Alone'],axis=1)\n",
    "result_model = DecisionTreeClassifier(criterion='gini',max_depth=4,random_state=0)\n",
    "result_model.fit(data_train[X_rfe],data_train[Target])\n",
    "Y_pred = result_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blas = pd.read_csv('Data/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": blas[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
